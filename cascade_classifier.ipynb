{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "frames_dir = 'preprocessed-frames'\n",
    "output_dir = 'bg-detection-frames'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# initialize the HOG descriptor/person detector\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "# loop over the image paths\n",
    "for i in tqdm(range(1, 290)):\n",
    "    # load the image and resize it to (1) reduce detection time\n",
    "    # and (2) improve detection accuracy\n",
    "    image = cv2.imread(f\"{frames_dir}/frame{100}.jpg\")\n",
    "    #image = imutils.resize(image, width=min(400, image.shape[1]))\n",
    "    orig = image.copy()\n",
    "    # detect people in the image\n",
    "    (rects, weights) = hog.detectMultiScale(\n",
    "        image, winStride=(4, 4), padding=(8, 8), scale=1.05)\n",
    "    print(rects)\n",
    "    # draw the original bounding boxes\n",
    "    for (x, y, w, h) in rects:\n",
    "        cv2.rectangle(orig, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    # apply non-maxima suppression to the bounding boxes using a\n",
    "    # fairly large overlap threshold to try to maintain overlapping\n",
    "    # boxes that are still people\n",
    "    rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "    #pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    "\n",
    "    # draw the final bounding boxes\n",
    "                            #pick\n",
    "    for (xA, yA, xB, yB) in rects:\n",
    "        cv2.rectangle(image, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "\n",
    "    # show some information on the number of bounding boxes\n",
    "    #filename = imagePath[imagePath.rfind(\"/\") + 1:]\n",
    "    #print(\"[INFO] {}: {} original boxes, {} after suppression\".format(\n",
    "    #    filename, len(rects), len(pick)))\n",
    "\n",
    "    # show the output images\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = cv2.VideoWriter(\"hog.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 15, (512,480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:21<00:00, 11.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the image and convert it to grayscale\n",
    "#frame_num=90\n",
    "output_dir=\"hog\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for i in tqdm(range(1, 250)):\n",
    "    image = cv2.imread(f\"{frames_dir}/frame{i}.jpg\")\n",
    "\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "    # Detect people in the image\n",
    "    locations, confidence = hog.detectMultiScale(image)\n",
    "    #locations\n",
    "\n",
    "    # Draw rectangles around the detected people\n",
    "    for (x, y, w, h) in locations:\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 5)\n",
    "        #plt.imshow(image)\n",
    "\n",
    "    # Display the image with detected people\n",
    "    #plt.imshow(image)\n",
    "    out.write(image)\n",
    "    cv2.imwrite(f\"{output_dir}/frame{i}.jpg\", image)    \n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.object_detection import non_max_suppression\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7/249 [00:11<06:27,  1.60s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 46\u001b[0m\n\u001b[0;32m     40\u001b[0m hog\u001b[38;5;241m.\u001b[39msetSVMDetector(cv2\u001b[38;5;241m.\u001b[39mHOGDescriptor_getDefaultPeopleDetector())\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Detect people in the image\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m#winStride controlla la granularità dello spostamento della finestra di rilevamento sull’immagine.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#padding gestisce il contesto extra attorno alla finestra di rilevamento.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m#scale controlla la creazione di una piramide di immagini per rilevare oggetti a dimensioni variabili.\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m locations, confidence \u001b[38;5;241m=\u001b[39m \u001b[43mhog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectMultiScale\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#                 4,4             8,8           1.05\u001b[39;49;00m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwinStride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.05\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m#locations\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Draw rectangles around the detected people\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (x, y, w, h) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(locations):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the image and convert it to grayscale\n",
    "#frame_num=90\n",
    "output_dir=\"hog-imutils\"\n",
    "\n",
    "frames_dir='preprocessed-frames-no-gaussian'\n",
    "out = cv2.VideoWriter(\"hog-imutils.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 15, (512,480))\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "ex_image = cv2.imread(f\"{frames_dir}/frame1.jpg\")\n",
    "#all the frame have the same dimention\n",
    "(height, width) = ex_image.shape[:2]\n",
    "desired_width=400\n",
    "if width<desired_width:\n",
    "    width=desired_width\n",
    "    ratio=desired_width/float(desired_width)\n",
    "    height=int(height*ratio)\n",
    "\n",
    "for i in tqdm(range(1, 250)):\n",
    "    image = cv2.imread(f\"{frames_dir}/frame{i}.jpg\")\n",
    "    \n",
    "    # resize → reduce detection time and  improve detection accuracy\n",
    "    # keep a minimum image size for accurate predictions\n",
    "    '''\n",
    "    if image.shape[1] < 400: # if image width < 400\n",
    "        (height, width) = image.shape[:2]\n",
    "        ratio = width / float(width) # find the width to height ratio\n",
    "        #frame_height = int(width * ratio)\n",
    "        image = cv2.resize(image, (400, width*ratio)) # resize the image according to the width to height ratio\n",
    "    '''\n",
    "    image = cv2.resize(image, (width, height)) # resize the image according to the width to height ratio\n",
    "\n",
    "    # Converti in scala di grigi e (opzionale) equalizza\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "    # Detect people in the image\n",
    "    #winStride controlla la granularità dello spostamento della finestra di rilevamento sull’immagine.\n",
    "    #padding gestisce il contesto extra attorno alla finestra di rilevamento.\n",
    "    #scale controlla la creazione di una piramide di immagini per rilevare oggetti a dimensioni variabili.\n",
    "    locations, confidence = hog.detectMultiScale(\n",
    "        #                 4,4             8,8           1.05\n",
    "        image, winStride=(4, 4), padding=(8, 8), scale=1.05)\n",
    "    #locations\n",
    "\n",
    "    # Draw rectangles around the detected people\n",
    "    for i, (x, y, w, h) in enumerate(locations):\n",
    "        if confidence[i] < 0.13:\n",
    "            cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 0), 2)\n",
    "        elif confidence[i] < 0.3 and confidence[i] > 0.13:\n",
    "            cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "        if confidence[i] < 0.7 and confidence[i] > 0.3:\n",
    "            cv2.rectangle(image, (x, y), (x+w, y+h), (50, 122, 255), 2)\n",
    "        if confidence[i] > 0.7:\n",
    "            cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    \n",
    "    # apply non-maxima suppression to the bounding boxes using a\n",
    "    # fairly large overlap threshold to try to maintain overlapping\n",
    "    # boxes that are still people\n",
    "    locations = np.array([[x, y, x + w, y + h] for (x, y, w, h) in locations])\n",
    "    pick = non_max_suppression(locations, probs=None, overlapThresh=0.65)\n",
    "\n",
    "    #final bounding boxes\n",
    "    for (xA, yA, xB, yB) in locations:\n",
    "        cv2.rectangle(image, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "    \n",
    "    original_dim_image = imutils.resize(image, width=512, height=480)\n",
    "    out.write(original_dim_image)\n",
    "    cv2.imwrite(f\"{output_dir}/frame{i}.jpg\", original_dim_image)    \n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
